{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import function,grad,pp,shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "ds = datasets.load_iris()\n",
    "train_data_x = ds['data'][:,0:2]\n",
    "train_data_y = ds['target']\n",
    "\n",
    "# plt.plot(x[y==0][:,0],x[y==0][:,1],'+r')\n",
    "# plt.plot(x[y==1][:,0],x[y==1][:,1],'+b')\n",
    "# plt.plot(x[y==2][:,0],x[y==2][:,1],'ob')\n",
    "\n",
    "# i = T.dscalar('i')\n",
    "# x = T.dmatrix('x')\n",
    "# y = T.ivector('y')\n",
    "# W = shared(value=np.random.uniform(low=-0.1,high=0.1,size=(2,1)))\n",
    "\n",
    "# z = T.dot(x,W) + y.reshape((150,1)) + i \n",
    "\n",
    "# f = function([i],z,givens=[[x,train_data_x],[y,train_data_y]])\n",
    "# f(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self,n_in,n_out):\n",
    "        self.x = T.matrix('x')\n",
    "        self.y = T.ivector('y')\n",
    "        self.W = shared(\n",
    "            value=np.random.uniform(low=-0.1,high=0.1,size=(n_in,n_out)),\n",
    "            name='W',\n",
    "            borrow=True\n",
    "        )\n",
    "        self.b = shared(\n",
    "            value=np.random.uniform(low=-0.1,high=0.1,size=(n_out,)),\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "        self.cost = T.mean((self.y.reshape((batch_size,1)) - T.tanh(T.dot(self.x ,self.W) + self.b)) ** 2)\n",
    "        self.output = None\n",
    "    \n",
    "train_set_x = shared(value=train_data_x,name='train_set_x',borrow=True)\n",
    "train_set_y = T.cast(shared(value=train_data_y,name='train_set_y',borrow=True),'int32')\n",
    "\n",
    "learning_rate = 0.01\n",
    "index = T.iscalar('index')\n",
    "model = LogisticRegression(2,1)\n",
    "g_w = grad(model.cost,model.W)\n",
    "g_b = grad(model.cost,model.b)\n",
    "\n",
    "train = function(inputs=[index],outputs=model.cost,\n",
    "         updates=[\n",
    "                 (model.W, model.W - learning_rate * g_w),\n",
    "                 (model.b, model.b - learning_rate * g_b)\n",
    "                 ],\n",
    "         givens=[(model.x,train_set_x[index * batch_size :(index+1) * batch_size ]),\n",
    "                 (model.y,train_set_y[index * batch_size :(index+1) * batch_size ])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0312188022015\n",
      "0.314632288372\n",
      "0.439194581232\n"
     ]
    }
   ],
   "source": [
    "print train(0)\n",
    "print train(1)\n",
    "print train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
